{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import get_ipython;   \n",
    "get_ipython().magic('reset -sf')\n",
    "\n",
    "import os\n",
    "os.chdir(\"C:/Users/Lenovo 4/Desktop/Data Quest Folder/Random Forest/\")\n",
    "os.getcwd()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math as math\n",
    "\n",
    "df = pd.read_csv(\"hour.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a histogram of the cnt column of bike_rentals, and take a look at the distribution of total rentals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATuElEQVR4nO3db6ye9X3f8fenOCFrusR2MMiznZkoVho6KcAscJZp6kJr/lUxD4IEqobFLHkP2JZMlTqzPbAKjUSkqaRIK6oV3JooC2E0GRZBYZZDNO0BBFMYARzmE0LxmSk+qQ1Zi5qV9LsH9+/Abeccn/s+Pvapz+/9km5d1+97/a77un73Zenj6899n1QVkqQ+/cJi74AkafEYApLUMUNAkjpmCEhSxwwBSerYssXegVO54IILav369Yu9G5J0Tnn66ad/XFWrRun7dzoE1q9fz4EDBxZ7NyTpnJLkz0bt6+UgSeqYISBJHTMEJKljhoAkdcwQkKSOzRkCST6W5Nmh10+SfD7JyiT7khxq0xWtf5Lck2QiyXNJLh96r62t/6EkW8/kwCRJc5szBKrqpaq6tKouBf4x8BbwTWAHsL+qNgD7WxvgWmBDe20H7gVIshLYCVwJXAHsnA4OSdLiGPdy0FXAD6vqz4AtwJ5W3wPc0Oa3APfXwBPA8iSrgauBfVV1rKqOA/uAa057BJKkeRs3BG4CvtbmL6qq1wDa9MJWXwMcHlpnstVmq58gyfYkB5IcmJqaGnP3JEnjGPkbw0neC3wGuH2urjPU6hT1EwtVu4BdABs3bjytv3izfse3Tmf1eXvlrusXZbuSNK5xzgSuBf60ql5v7dfbZR7a9GirTwLrhtZbCxw5RV2StEjGCYGbefdSEMBeYPoJn63Aw0P1W9pTQpuAN9vloseAzUlWtBvCm1tNkrRIRroclOQXgV8H/tVQ+S7gwSTbgFeBG1v9UeA6YILBk0S3AlTVsSR3Ak+1fndU1bHTHoEkad5GCoGqegv40Em1v2DwtNDJfQu4bZb32Q3sHn83JUlngt8YlqSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSx0YKgSTLkzyU5AdJDib5ZJKVSfYlOdSmK1rfJLknyUSS55JcPvQ+W1v/Q0m2nqlBSZJGM+qZwO8D366qXwY+ARwEdgD7q2oDsL+1Aa4FNrTXduBegCQrgZ3AlcAVwM7p4JAkLY45QyDJB4B/BtwHUFX/r6reALYAe1q3PcANbX4LcH8NPAEsT7IauBrYV1XHquo4sA+4ZkFHI0kayyhnAh8BpoA/SvJMki8neT9wUVW9BtCmF7b+a4DDQ+tPttpsdUnSIhklBJYBlwP3VtVlwF/x7qWfmWSGWp2ifuLKyfYkB5IcmJqaGmH3JEnzNUoITAKTVfVkaz/EIBReb5d5aNOjQ/3XDa2/FjhyivoJqmpXVW2sqo2rVq0aZyySpDHNGQJV9efA4SQfa6WrgBeBvcD0Ez5bgYfb/F7glvaU0CbgzXa56DFgc5IV7Ybw5laTJC2SZSP2+zfAV5O8F3gZuJVBgDyYZBvwKnBj6/socB0wAbzV+lJVx5LcCTzV+t1RVccWZBSSpHkZKQSq6llg4wyLrpqhbwG3zfI+u4Hd4+ygJOnM8RvDktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0bKQSSvJLk+0meTXKg1VYm2ZfkUJuuaPUkuSfJRJLnklw+9D5bW/9DSbaemSFJkkY1zpnAP6+qS6tqY2vvAPZX1QZgf2sDXAtsaK/twL0wCA1gJ3AlcAWwczo4JEmL43QuB20B9rT5PcANQ/X7a+AJYHmS1cDVwL6qOlZVx4F9wDWnsX1J0mkaNQQK+O9Jnk6yvdUuqqrXANr0wlZfAxweWney1WarnyDJ9iQHkhyYmpoafSSSpLEtG7Hfp6rqSJILgX1JfnCKvpmhVqeon1io2gXsAti4cePPLZckLZyRzgSq6kibHgW+yeCa/uvtMg9terR1nwTWDa2+FjhyirokaZHMGQJJ3p/k70/PA5uB54G9wPQTPluBh9v8XuCW9pTQJuDNdrnoMWBzkhXthvDmVpMkLZJRLgddBHwzyXT//1JV307yFPBgkm3Aq8CNrf+jwHXABPAWcCtAVR1LcifwVOt3R1UdW7CRSJLGNmcIVNXLwCdmqP8FcNUM9QJum+W9dgO7x99NSdKZ4DeGJaljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjo2cggkOS/JM0keae2LkzyZ5FCSryd5b6uf39oTbfn6ofe4vdVfSnL1Qg9GkjSecc4EPgccHGp/Ebi7qjYAx4Ftrb4NOF5VHwXubv1IcglwE/ArwDXAHyQ57/R2X5J0OkYKgSRrgeuBL7d2gE8DD7Uue4Ab2vyW1qYtv6r13wI8UFU/raofARPAFQsxCEnS/Ix6JvAl4LeBv23tDwFvVNXbrT0JrGnza4DDAG35m63/O/UZ1nlHku1JDiQ5MDU1NcZQJEnjmjMEkvwGcLSqnh4uz9C15lh2qnXeLVTtqqqNVbVx1apVc+2eJOk0LBuhz6eAzyS5Dngf8AEGZwbLkyxr/9tfCxxp/SeBdcBkkmXAB4FjQ/Vpw+tIkhbBnGcCVXV7Va2tqvUMbux+p6p+E3gc+GzrthV4uM3vbW3a8u9UVbX6Te3poYuBDcD3FmwkkqSxjXImMJt/DzyQ5HeBZ4D7Wv0+4CtJJhicAdwEUFUvJHkQeBF4G7itqn52GtuXJJ2msUKgqr4LfLfNv8wMT/dU1V8DN86y/heAL4y7k5KkM8NvDEtSxwwBSeqYISBJHTudG8Oaxfod31qU7b5y1/WLsl1J5y7PBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljc4ZAkvcl+V6S/5XkhSS/0+oXJ3kyyaEkX0/y3lY/v7Un2vL1Q+91e6u/lOTqMzUoSdJoRjkT+Cnw6ar6BHApcE2STcAXgburagNwHNjW+m8DjlfVR4G7Wz+SXALcBPwKcA3wB0nOW8jBSJLGM2cI1MBftuZ72quATwMPtfoe4IY2v6W1acuvSpJWf6CqflpVPwImgCsWZBSSpHkZ6Z5AkvOSPAscBfYBPwTeqKq3W5dJYE2bXwMcBmjL3wQ+NFyfYZ3hbW1PciDJgampqfFHJEka2UghUFU/q6pLgbUM/vf+8Zm6tWlmWTZb/eRt7aqqjVW1cdWqVaPsniRpnsZ6Oqiq3gC+C2wClidZ1hatBY60+UlgHUBb/kHg2HB9hnUkSYtglKeDViVZ3ub/HvBrwEHgceCzrdtW4OE2v7e1acu/U1XV6je1p4cuBjYA31uogUiSxrds7i6sBva0J3l+AXiwqh5J8iLwQJLfBZ4B7mv97wO+kmSCwRnATQBV9UKSB4EXgbeB26rqZws7HEnSOOYMgap6DrhshvrLzPB0T1X9NXDjLO/1BeAL4++mJOlM8BvDktQxQ0CSOmYISFLHDAFJ6tgoTwfpHLF+x7cWbduv3HX9om1b0vx5JiBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLH5gyBJOuSPJ7kYJIXknyu1Vcm2ZfkUJuuaPUkuSfJRJLnklw+9F5bW/9DSbaeuWFJkkYxypnA28BvVdXHgU3AbUkuAXYA+6tqA7C/tQGuBTa013bgXhiEBrATuBK4Atg5HRySpMUxZwhU1WtV9adt/v8CB4E1wBZgT+u2B7ihzW8B7q+BJ4DlSVYDVwP7qupYVR0H9gHXLOhoJEljGeueQJL1wGXAk8BFVfUaDIICuLB1WwMcHlptstVmq5+8je1JDiQ5MDU1Nc7uSZLGNHIIJPkl4E+Az1fVT07VdYZanaJ+YqFqV1VtrKqNq1atGnX3JEnzMFIIJHkPgwD4alV9o5Vfb5d5aNOjrT4JrBtafS1w5BR1SdIiGeXpoAD3AQer6veGFu0Fpp/w2Qo8PFS/pT0ltAl4s10uegzYnGRFuyG8udUkSYtk2Qh9PgX8C+D7SZ5ttf8A3AU8mGQb8CpwY1v2KHAdMAG8BdwKUFXHktwJPNX63VFVxxZkFJKkeZkzBKrqfzLz9XyAq2boX8Bts7zXbmD3ODsoSTpz/MawJHXMEJCkjhkCktQxQ0CSOjbK00HSnNbv+NaibPeVu65flO1KS4VnApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjs0ZAkl2Jzma5Pmh2sok+5IcatMVrZ4k9ySZSPJcksuH1tna+h9KsvXMDEeSNI5RzgT+GLjmpNoOYH9VbQD2tzbAtcCG9toO3AuD0AB2AlcCVwA7p4NDkrR45gyBqvofwLGTyluAPW1+D3DDUP3+GngCWJ5kNXA1sK+qjlXVcWAfPx8skqSzbL5/Y/iiqnoNoKpeS3Jhq68BDg/1m2y12eo/J8l2BmcRfPjDH57n7qkXi/W3jcG/b6ylYaFvDGeGWp2i/vPFql1VtbGqNq5atWpBd06SdKL5hsDr7TIPbXq01SeBdUP91gJHTlGXJC2i+YbAXmD6CZ+twMND9VvaU0KbgDfbZaPHgM1JVrQbwptbTZK0iOa8J5Dka8CvAhckmWTwlM9dwINJtgGvAje27o8C1wETwFvArQBVdSzJncBTrd8dVXXyzWZJ0lk2ZwhU1c2zLLpqhr4F3DbL++wGdo+1d5KkM8pvDEtSxwwBSeqYISBJHTMEJKlj8/3GsNS9xfq2st9U1kLyTECSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMb8sJp1j/JOaWkieCUhSxwwBSeqYISBJHTMEJKlj3hiWNDJ/OXXp8UxAkjrmmYCkv/M8AzlzzvqZQJJrkryUZCLJjrO9fUnSu85qCCQ5D/jPwLXAJcDNSS45m/sgSXrX2b4cdAUwUVUvAyR5ANgCvHiW90OS5tTDt7PPdgisAQ4PtSeBK4c7JNkObG/Nv0zy0jy3dQHw43mue67rdeyOuz9Lduz54ikXzzXufzjqds52CGSGWp3QqNoF7DrtDSUHqmrj6b7PuajXsTvu/vQ69oUc99m+MTwJrBtqrwWOnOV9kCQ1ZzsEngI2JLk4yXuBm4C9Z3kfJEnNWb0cVFVvJ/nXwGPAecDuqnrhDG3utC8pncN6Hbvj7k+vY1+wcaeq5u4lSVqS/NkISeqYISBJHVuSIbCUf5oiybokjyc5mOSFJJ9r9ZVJ9iU51KYrWj1J7mmfxXNJLl/cEZyeJOcleSbJI619cZIn27i/3h44IMn5rT3Rlq9fzP0+XUmWJ3koyQ/asf9kD8c8yb9r/86fT/K1JO9bqsc8ye4kR5M8P1Qb+xgn2dr6H0qyda7tLrkQ6OCnKd4GfquqPg5sAm5r49sB7K+qDcD+1obB57ChvbYD9579XV5QnwMODrW/CNzdxn0c2Nbq24DjVfVR4O7W71z2+8C3q+qXgU8w+AyW9DFPsgb4t8DGqvpHDB4muYmle8z/GLjmpNpYxzjJSmAngy/hXgHsnA6OWVXVknoBnwQeG2rfDty+2Pt1Bsf7MPDrwEvA6lZbDbzU5v8QuHmo/zv9zrUXg++V7Ac+DTzC4MuHPwaWnXzsGTyB9sk2v6z1y2KPYZ7j/gDwo5P3f6kfc979hYGV7Rg+Aly9lI85sB54fr7HGLgZ+MOh+gn9ZnotuTMBZv5pijWLtC9nVDvdvQx4Erioql4DaNMLW7el9Hl8Cfht4G9b+0PAG1X1dmsPj+2dcbflb7b+56KPAFPAH7VLYV9O8n6W+DGvqv8D/CfgVeA1Bsfwafo45tPGPcZjH/ulGAJz/jTFUpDkl4A/AT5fVT85VdcZaufc55HkN4CjVfX0cHmGrjXCsnPNMuBy4N6qugz4K969LDCTJTH2dhljC3Ax8A+A9zO4DHKypXjM5zLbWMf+DJZiCCz5n6ZI8h4GAfDVqvpGK7+eZHVbvho42upL5fP4FPCZJK8ADzC4JPQlYHmS6S89Do/tnXG35R8Ejp3NHV5Ak8BkVT3Z2g8xCIWlfsx/DfhRVU1V1d8A3wD+CX0c82njHuOxj/1SDIEl/dMUSQLcBxysqt8bWrQXmH4SYCuDewXT9Vva0wSbgDenTy/PJVV1e1Wtrar1DI7pd6rqN4HHgc+2biePe/rz+Gzrf07+r7Cq/hw4nORjrXQVg59fX9LHnMFloE1JfrH9u58e95I/5kPGPcaPAZuTrGhnUptbbXaLfSPkDN1cuQ7438APgf+42PuzwGP7pwxO754Dnm2v6xhc+9wPHGrTla1/GDwt9UPg+wyetFj0cZzmZ/CrwCNt/iPA94AJ4L8C57f6+1p7oi3/yGLv92mO+VLgQDvu/w1Y0cMxB34H+AHwPPAV4PylesyBrzG49/E3DP5Hv20+xxj4l+0zmABunWu7/myEJHVsKV4OkiSNyBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHfv/Crkyh2wl50YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    17379.000000\n",
       "mean       189.463088\n",
       "std        181.387599\n",
       "min          1.000000\n",
       "25%         40.000000\n",
       "50%        142.000000\n",
       "75%        281.000000\n",
       "max        977.000000\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(df[\"cnt\"])\n",
    "plt.show()\n",
    "df.cnt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant       0.278379\n",
      "season        0.178056\n",
      "yr            0.250495\n",
      "mnth          0.120638\n",
      "hr            0.394071\n",
      "holiday      -0.030927\n",
      "weekday       0.026900\n",
      "workingday    0.030284\n",
      "weathersit   -0.142426\n",
      "temp          0.404772\n",
      "atemp         0.400929\n",
      "hum          -0.322911\n",
      "windspeed     0.093234\n",
      "casual        0.694564\n",
      "registered    0.972151\n",
      "cnt           1.000000\n",
      "Name: cnt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Use the corr method on the bike_rentals dataframe to explore how each column is correlated with cnt.\n",
    "corrmat = df.corr()[\"cnt\"]\n",
    "print(corrmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables \"casual\" and \"registrered\" seems to be highly correlated. Consider dropping these variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a function to re-categorize observations in \"hr\"  \n",
    "def assign_label(hour):\n",
    "    if hour >=0 and hour < 6:\n",
    "        return 4\n",
    "    elif hour >=6 and hour < 12:\n",
    "        return 1\n",
    "    elif hour >= 12 and hour < 18:\n",
    "        return 2\n",
    "    elif hour >= 18 and hour <=24:\n",
    "        return 3\n",
    "df[\"time_label\"] = df[\"hr\"].apply(assign_label)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80 /20 split \n",
    "# Shuffle the rows  \n",
    "# This permutes the index randomly using numpy.random.permutation\n",
    "# Then, it reindexes the dataframe with the result\n",
    "# The net effect is to put the rows into random order\n",
    "np.random.seed(1)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "row = math.floor(df.shape[0]*.8)\n",
    "\n",
    "train = df.iloc[:row]\n",
    "test = df.iloc[row:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1: Linear Regression\n",
    "#Many columns are correlated with \"cnt\" variable \n",
    "# linear regression works best when predictors are linearly correlated to the target and also independent\n",
    "# linear regression is fairly resistant to overfitting, prone to underfitting, and may not be a good model overall\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "predictors = list(train.columns)\n",
    "predictors.remove(\"cnt\")\n",
    "predictors.remove(\"casual\")\n",
    "predictors.remove(\"registered\")\n",
    "predictors.remove(\"dteday\")\n",
    "\n",
    "reg1 = LinearRegression()\n",
    "reg1.fit(train[predictors], train[\"cnt\"])\n",
    "predictions = reg1.predict(test[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17052.124871247568\n",
      "130.5837848710458\n"
     ]
    }
   ],
   "source": [
    "## MSE \n",
    "# We will use sklearn's package to calculate error metrics, but they can be coded too, as shown below.\n",
    "# numpy.mean((predictions - test[\"cnt\"]) ** 2)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(test[\"cnt\"], predictions)\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2731.2018678794934\n",
      "52.26090190457388\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Decision Trees \n",
    "# Decision trees tend to overfit, so adjusting parameters are essential \n",
    "# Decision trees suffer from instability: small changes in input data can result in a different output model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# max_depth - Globally restricts how deep the tree can go\n",
    "# min_samples_split - The minimum number of rows a node should have before it can be split; if this is set to 2, for example, then nodes with 2 rows won't be split, and will become leaves instead\n",
    "# min_samples_leaf - The minimum number of rows a leaf must have\n",
    "# min_weight_fraction_leaf - The fraction of input rows a leaf must have\n",
    "# max_leaf_nodes - The maximum number of total leaves; this will cap the count of leaf nodes as the tree is being built\n",
    "reg2 = DecisionTreeRegressor(min_samples_leaf=5)\n",
    "# fit the tree\n",
    "reg2.fit(train[predictors], train[\"cnt\"])\n",
    "\n",
    "predictions2 = reg2.predict(test[predictors])\n",
    "\n",
    "# MSE  \n",
    "mse = mean_squared_error(test[\"cnt\"], predictions2)\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " drasticallly reduced mse, decision trees take into account the non-linear predictors that are in our dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Random Forests \n",
    "# Ensembles combine the predictions of multiple models to create a more accurate final prediction. \n",
    "# Bagging and random feature subsets are integrated in the Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "# We instantiate a \"RandomForestRegressor\" by passing in paramteres that apply to individual trees:\n",
    "# min_samples_leaf =5 The minimum number of rows a leaf must have\n",
    "# We can also apply parameters specific to the random forest that alter its overall construction:\n",
    "# n_estimators =5, indicates how many trees to build, has diminishing returns as it goes higher, it takes longer as well \n",
    "# boostrap = default is TRUE \n",
    "reg3 = RandomForestRegressor(n_estimators= 100, min_samples_leaf =5, random_state = 1)\n",
    "reg3.fit(train[predictors],train[\"cnt\"])\n",
    "predictions3 = reg3.predict(test[predictors])\n",
    "predictions_train_3 = reg3.predict(train[predictors])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976.6020083258209\n",
      "2063.424559507605\n",
      "45.42493323613811\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "mse_train = mean_squared_error(train[\"cnt\"], predictions_train_3)\n",
    "print(mse_train)\n",
    "mse = mean_squared_error(test[\"cnt\"], predictions3)\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432.4824021430636\n",
      "1881.571926808211\n",
      "43.377089884041446\n"
     ]
    }
   ],
   "source": [
    "# with the min_samples_leaf parameter tweaked, MSE decreased about 200\n",
    "# However, compare the values 432 vs. 1881, our model is overfitting to the training data \n",
    "\n",
    "reg3 = RandomForestRegressor(n_estimators= 100, min_samples_leaf =2, random_state = 1)\n",
    "reg3.fit(train[predictors],train[\"cnt\"])\n",
    "predictions3 = reg3.predict(test[predictors])\n",
    "predictions_train_3 = reg3.predict(train[predictors])\n",
    "# MSE\n",
    "mse_train = mean_squared_error(train[\"cnt\"], predictions_train_3)\n",
    "print(mse_train)\n",
    "mse = mean_squared_error(test[\"cnt\"], predictions3)\n",
    "print(mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028.4542141344066\n",
      "2229.077479390863\n",
      "47.213107071986514\n"
     ]
    }
   ],
   "source": [
    "# Compare the values 432 vs. 1881, our model is overfitting to the training data \n",
    "# we might want to tweak parameteres such as max_depth to resolve overfitting \n",
    "\n",
    "reg3 = RandomForestRegressor(n_estimators= 100, min_samples_leaf =2, random_state = 1, max_depth =12)\n",
    "reg3.fit(train[predictors],train[\"cnt\"])\n",
    "predictions3 = reg3.predict(test[predictors])\n",
    "predictions_train_3 = reg3.predict(train[predictors])\n",
    "# MSE\n",
    "mse_train = mean_squared_error(train[\"cnt\"], predictions_train_3)\n",
    "print(mse_train)\n",
    "mse = mean_squared_error(test[\"cnt\"], predictions3)\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 1,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# tweaking paramters does not seem to work efficiently\n",
    "# Instead, we turn to: \n",
    "# Using Scikit-Learnâ€™s RandomizedSearchCV method, we can define a grid of hyperparameter ranges, \n",
    "# and randomly sample from the grid, performing K-Fold CV with each combination of values.\n",
    "\n",
    "#To look at the available hyperparameters, we can create a random forest and \n",
    "# examine the default values.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state = 1)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())\n",
    "\n",
    "#Parameters currently in use:\n",
    " #    {'bootstrap': True,\n",
    " # 'ccp_alpha': 0.0,\n",
    " # 'criterion': 'mse',\n",
    " # 'max_depth': None,\n",
    " # 'max_features': 'auto',\n",
    " # 'max_leaf_nodes': None,\n",
    " # 'max_samples': None,\n",
    " # 'min_impurity_decrease': 0.0,\n",
    " # 'min_impurity_split': None,\n",
    " # 'min_samples_leaf': 1,\n",
    " # 'min_samples_split': 2,\n",
    " # 'min_weight_fraction_leaf': 0.0,\n",
    " # 'n_estimators': 100,\n",
    " # 'n_jobs': None,\n",
    " # 'oob_score': False,\n",
    " # 'random_state': 1,\n",
    " # 'verbose': 0,\n",
    " # 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 344, 488, 633, 777, 922, 1066, 1211, 1355, 1500]}\n"
     ]
    }
   ],
   "source": [
    "#Random Hyperparameter Grid\n",
    "\n",
    "#To use RandomizedSearchCV, we first need to create a parameter grid to sample from during fitting:\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200 , stop = 1500, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "#On each iteration, the algorithm will choose a difference combination of the features. \n",
    "# we instantiate the random search and fit it like any Scikit-Learn model:\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "reg4 = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "# n_iter, which controls the number of different combinations to try\n",
    "# cv, which is the number of folds to use for cross validation (we use 100 and 3 respectively)\n",
    "\n",
    "#More iterations will cover a wider search space and more cv folds reduces the chances of overfitting, \n",
    "# but raising each will increase the run time\n",
    "reg4_random = RandomizedSearchCV(estimator = reg4, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "reg4_random.fit(train[predictors], train[\"cnt\"])\n",
    "\n",
    "# We can view the best parameters from fitting the random search:\n",
    "reg4_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From these results, we narrow the range of values for each hyperparameter.\n",
    "# To determine if random search yielded a better model, we compare the base model with the best random search model.\n",
    "def evaluate(model, test_features, test_labels, train_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    mse = mean_squared_error(test_labels, predictions)\n",
    "    mse_train = mean_squared_error(train_labels, predictions)\n",
    "    print('Model Performance')\n",
    "    print('MSE: {:0.4f} .'.format(np.mean(mse)))\n",
    "    print('Model Performance on training data')\n",
    "    print('MSE: {:0.4f} .'.format(np.mean(mse_train)))\n",
    "    return mse\n",
    "\n",
    "#base model\n",
    "base_model = RandomForestRegressor(n_estimators = 100, random_state = 1, max_depth =12)\n",
    "base_model.fit(train[predictors],train[\"cnt\"])\n",
    "base_mse= evaluate(base_model, test[predictors], test[\"cnt\"], train[\"cnt\"])\n",
    "\n",
    "#best model\n",
    "best_random = reg4_random.best_estimator_\n",
    "random_mse = evaluate(best_random, test[predictors], test[\"cnt\"], train[\"cnt\"])\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (base_mse - random_mse) / base_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can further improve our results by using grid search to focus on \n",
    "# the most promising hyperparameters ranges found in the random search.\n",
    "# Use GridSearchCV to evaluate all combinations we define instead of randomly sampling from a distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "reg4_random.best_params_\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [95, 100, 105],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [1,2,3],\n",
    "    'min_samples_split': [1,2,3],\n",
    "    'n_estimators': [1200,1300,1366,1400],\n",
    "    }\n",
    "\n",
    "# create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model \n",
    "grid_search = GridSearchCV(estimator =  rf, param_grid = param_grid, cv=3, n_jobs = -1, verbose =2) \n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(train[predictors], train[\"cnt\"])\n",
    "grid_search.best_params_\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_mse = evaluate(best_grid, test[predictors], test[\"cnt\"], train[\"cnt\"])\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_mse - grid_mse) / random_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
